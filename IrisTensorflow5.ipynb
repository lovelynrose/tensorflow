{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IrisTensorflow5.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lovelynrose/tensorflow/blob/master/IrisTensorflow5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViEDqudGaRbN",
        "colab_type": "text"
      },
      "source": [
        "#Simple Classification using tensorflow\n",
        "\n",
        "*   Sequential creates a sequence of layers\n",
        "*   Dense creates a fully connected network\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18SppJESY164",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htL0FMcibjl1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.preprocessing import StandardScaler,OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3JVDDX8bsYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeTriLTObwgn",
        "colab_type": "code",
        "outputId": "d6278e3e-2722-47ef-c2b1-7c5809e7f28a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(iris.feature_names)\n",
        "print(iris.target_names)\n",
        "#print(iris.DESCR)\n",
        "#print(iris.data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
            "['setosa' 'versicolor' 'virginica']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM0EDqI7dBy-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_data = iris.data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA4eQ2z4cPW8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_class = iris.target\n",
        "#iris['target']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YdMc0Va9ebEr",
        "colab_type": "text"
      },
      "source": [
        "###Use z-score normalization to convert data with mean 0 and variance 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x57GIpKJdSS-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "scaler = StandardScaler()\n",
        "input_scaled = scaler.fit_transform(input_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpKTaV2lmJ61",
        "colab_type": "code",
        "outputId": "4afa96c4-58a9-4287-f238-15ad31d385b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "# One hot encoding\n",
        "enc = OneHotEncoder()\n",
        "hot_target_class = enc.fit_transform(target_class[:, np.newaxis]).toarray()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/_encoders.py:415: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
            "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
            "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tq7XYLCaeUHl",
        "colab_type": "text"
      },
      "source": [
        "###Split into training and testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLRqJfAdeg4d",
        "colab_type": "code",
        "outputId": "5d6368a6-88e7-4ec6-c76e-68f62b77d17e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "x_train,x_test,y_train,y_test = train_test_split(input_scaled,hot_target_class,test_size=0.3)\n",
        "#x_train\n",
        "y_train"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 1., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqNJBtVinVXk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to np arrays so that we can use with TensorFlow\n",
        "x_train = np.array(x_train).astype(np.float32)\n",
        "x_test  = np.array(x_test).astype(np.float32)\n",
        "y_train = np.array(y_train).astype(np.float32)\n",
        "y_test  = np.array(y_test).astype(np.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AVY3C-jEgwYC",
        "colab_type": "text"
      },
      "source": [
        "###Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csEvoq30ZZbB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_features = 4\n",
        "n_hnode1 = 5\n",
        "n_hnode2 = 8\n",
        "n_node = 3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SGe3Spzzaq7j",
        "colab_type": "text"
      },
      "source": [
        "###Can add any number of layers using model.add\n",
        "\n",
        "\n",
        "*   Compulsorily the first add function must have the parameter input_dim\n",
        "*   Default activation is linear function\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHWkWPaPZfGP",
        "colab_type": "code",
        "outputId": "5b4cee39-954e-44e0-e3c4-49f25bdd2b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "w = {'hidden1': tf.Variable(initial_value=np.random.random([n_features,n_hnode1]),name='weight_hidden1'),\n",
        "     'hidden2' : tf.Variable(initial_value=np.random.random([n_hnode1,n_hnode2]),name='weight_hidden2'),\n",
        "     'output': tf.Variable(initial_value=np.random.random([n_hnode2,n_node]),name='weight_output')\n",
        "    }\n",
        "w\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hidden1': <tf.Variable 'weight_hidden1:0' shape=(4, 5) dtype=float64_ref>,\n",
              " 'hidden2': <tf.Variable 'weight_hidden2:0' shape=(5, 8) dtype=float64_ref>,\n",
              " 'output': <tf.Variable 'weight_output:0' shape=(8, 3) dtype=float64_ref>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsyMpnQdk_-c",
        "colab_type": "code",
        "outputId": "93157533-7a39-4dab-db5d-61df0bd02969",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "b = {'hidden1':tf.Variable(initial_value=np.ones([n_hnode1]),name='bias_hidden1'),\n",
        "     'hidden2':tf.Variable(initial_value=np.ones([n_hnode2]),name='bias_hidden2'),\n",
        "     'output':tf.Variable(initial_value=np.ones([n_node]),name='bias_output')\n",
        "    }\n",
        "b"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hidden1': <tf.Variable 'bias_hidden1:0' shape=(5,) dtype=float64_ref>,\n",
              " 'hidden2': <tf.Variable 'bias_hidden2:0' shape=(8,) dtype=float64_ref>,\n",
              " 'output': <tf.Variable 'bias_output:0' shape=(3,) dtype=float64_ref>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3NekGWClJyj",
        "colab_type": "code",
        "outputId": "3f22577e-2806-41db-a21b-aa60fd2349e9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x = tf.placeholder(tf.float64,shape=(None,n_features),name='input')\n",
        "y = tf.placeholder(tf.float64,shape=(None,n_node),name='output')\n",
        "x\n",
        "y"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'output:0' shape=(?, 3) dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wGTS7e5lQAd",
        "colab_type": "code",
        "outputId": "eb9f8e0e-682c-474c-969c-829bcddbe66c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "hidden_layer1 = tf.add(tf.matmul(x, w['hidden1']), b['hidden1'])\n",
        "hidden_layer1 = tf.nn.relu(hidden_layer1)\n",
        "\n",
        "hidden_layer2 = tf.add(tf.matmul(hidden_layer1, w['hidden2']), b['hidden2'])\n",
        "hidden_layer2 = tf.nn.relu(hidden_layer2)\n",
        "\n",
        "output_layer = tf.add(tf.matmul(hidden_layer2, w['output']),b['output'])\n",
        "output_layer=tf.nn.softmax(output_layer)\n",
        "output_layer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'Softmax:0' shape=(?, 3) dtype=float64>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wopEmikabAz9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Compile model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EznBdyTqg4dj",
        "colab_type": "code",
        "outputId": "95d4e401-1699-439c-e5ba-9dc7b71c8502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "cost = tf.losses.softmax_cross_entropy(y_train,output_layer)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0807 13:22:50.000775 140182841051008 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_fOn5emhQnS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = tf.train.AdamOptimizer(0.01).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB0mhXOvq-Lg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc,acc_op = tf.metrics.accuracy(labels=tf.math.argmax(y,1),predictions=tf.math.argmax(output_layer,1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjOAs9liiLLt",
        "colab_type": "text"
      },
      "source": [
        "###Fit model\n",
        "\n",
        "*   Epoch - how many passes through the training dataset\n",
        "*   Batch - how many samples to consider before updating the weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5LjdqvPjThF",
        "colab_type": "code",
        "outputId": "c2772206-df7e-4ddd-ae6f-d64597d078ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(\"Prediction: {}\".format(tf.math.argmax(output_layer,1)))\n",
        "print(\"    Labels: {}\".format(tf.math.argmax(y_train,1)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prediction: Tensor(\"ArgMax_2:0\", shape=(?,), dtype=int64)\n",
            "    Labels: Tensor(\"ArgMax_3:0\", shape=(105,), dtype=int64)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rgx38Bluifd2",
        "colab_type": "code",
        "outputId": "7fb92cd9-6c67-4c4a-ec78-c1f31a9fcf89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  init = tf.global_variables_initializer()\n",
        "  init_l = tf.local_variables_initializer()\n",
        "  sess.run(init)\n",
        "  sess.run(init_l)\n",
        "  for epoch in range(0,5):\n",
        "    out = sess.run([opt,cost],feed_dict={x:x_train,y:y_train})\n",
        "    #print(out)\n",
        "  print(sess.run([acc,acc_op],feed_dict={x:x_train,y:y_train}))\n",
        "  #print(opt)\n",
        "  #print(cost)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.0, 0.2761905]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x_pAG7IFnnqv",
        "colab_type": "code",
        "outputId": "48c5fb3d-188d-4e6f-cd1c-a96ee90abf9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "import tensorboardcolab as tb\n",
        "tfb = tb.TensorBoardColab() #Must be in same cell\n",
        "writer = tfb.get_writer()\n",
        "writer.add_graph(tf.get_default_graph()) # add the graph \n",
        "writer.flush()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0807 13:26:42.639859 140182841051008 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/tensorboardcolab/core.py:49: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TensorBoard link:\n",
            "https://ff49f43e.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqUfJVYEQHMP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}